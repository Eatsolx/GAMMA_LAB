{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YqM5Z7qKUgqS"
      },
      "source": [
        "In this week, you are required to implement a toy GATConv and SAGEConv based on document. Also, you need to implement both in PyG and DGL. In this work, you will get a further understanding of tensor-centric in PyG and graph-centric in DGL."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "mclJkxgsUbRY"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "import torch.nn as nn\n",
        "import dgl\n",
        "import dgl.function as fn\n",
        "import torch.nn.functional as F\n",
        "from torch_geometric.nn.conv import MessagePassing\n",
        "from torch_geometric.utils import add_self_loops, degree\n",
        "\n",
        "class PyG_GATConv(MessagePassing):\n",
        "  def __init__(self, in_channel, out_channel):\n",
        "    super().__init__(aggr='add')\n",
        "\n",
        "    self.W = nn.Linear(in_channel, out_channel, bias=False)\n",
        "    self.a = nn.Linear(2*out_channel, 1, bias=False)\n",
        "    self.dropout = nn.Dropout(0.1)\n",
        "    \n",
        "    nn.init.xavier_uniform_(self.W.weight, gain=1.414)\n",
        "    nn.init.xavier_uniform_(self.a.weight, gain=1.414)\n",
        "\n",
        "  def forward(self, x, edge_index):\n",
        "    x = self.W(x)\n",
        "    edge_index, _ = add_self_loops(edge_index, num_nodes=x.size(0))\n",
        "    out = self.propagate(edge_index, x=x)\n",
        "    return out\n",
        "\n",
        "  def message(self, x_i, x_j, edge_index):\n",
        "    x_cat = torch.cat([x_i, x_j], dim=-1)\n",
        "    e = F.leaky_relu(self.a(x_cat), negative_slope=0.2)\n",
        "\n",
        "    node_i = edge_index[1]\n",
        "    e = self.dropout(e)\n",
        "    e = torch.exp(e)\n",
        "    input = torch.zeros_like(e)\n",
        "    e_sum = torch.scatter_add(input=input, dim=0, index=node_i.unsqueeze(1), src=e)\n",
        "    alpha = e / (e_sum[node_i] + 1e-16)\n",
        "\n",
        "    return alpha * x_j\n",
        "\n",
        "class PyG_SAGEConv(MessagePassing):\n",
        "  def __init__(self, in_channel, out_channel):\n",
        "    super().__init__(aggr='mean')\n",
        "\n",
        "    self.lin = nn.Linear(2*in_channel, out_channel)\n",
        "\n",
        "    nn.init.xavier_uniform_(self.lin.weight, gain=1.414)\n",
        "    if self.lin.bias is not None:\n",
        "      nn.init.zeros_(self.lin.bias)\n",
        "\n",
        "  def forward(self, x, edge_index):\n",
        "    edge_index, _ = add_self_loops(edge_index, num_nodes=x.size(0))\n",
        "    agg_neighbors = self.propagate(edge_index, x=x)\n",
        "    x_cat = torch.cat([x, agg_neighbors], dim=-1)\n",
        "\n",
        "    out = self.lin(x_cat)\n",
        "    return out\n",
        "\n",
        "  def message(self, x_j):\n",
        "    return x_j"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "HbdLhvBSVYEr"
      },
      "outputs": [],
      "source": [
        "class DGL_GATConv(nn.Module):\n",
        "  def __init__(self, in_channel, out_channel):\n",
        "    super().__init__()\n",
        "    self.W = nn.Linear(in_channel, out_channel, bias=False)\n",
        "    self.a = nn.Linear(2*out_channel, 1, bias=False)\n",
        "    self.dropout = nn.Dropout(0.1)\n",
        "    \n",
        "    nn.init.xavier_uniform_(self.W.weight, gain=1.414)\n",
        "    nn.init.xavier_uniform_(self.a.weight, gain=1.414)\n",
        "\n",
        "  def forward(self, g, h):\n",
        "    h = self.W(h)\n",
        "    g = dgl.add_self_loop(g)\n",
        "    g.ndata['h'] = h\n",
        "\n",
        "    def msg_func(edges):\n",
        "      x_cat = torch.cat([edges.dst['h'], edges.src['h']], dim=-1)\n",
        "      e = F.leaky_relu(self.a(x_cat), negative_slope=0.2)\n",
        "      return {'e': self.dropout(torch.exp(e))}\n",
        "\n",
        "    g.apply_edges(msg_func)\n",
        "\n",
        "    g.update_all(\n",
        "      fn.copy_e('e', 'm'),\n",
        "      fn.sum('m', 'e_sum')\n",
        "    )\n",
        "\n",
        "    v = g.edges()[1]\n",
        "    g.edata['alpha'] = g.edata['e'] / (g.ndata['e_sum'][v] + 1e-16)\n",
        "\n",
        "    g.update_all(\n",
        "      fn.u_mul_e('h', 'alpha', 'm'),\n",
        "      fn.sum('m', 'h_out')\n",
        "    )\n",
        "\n",
        "    out = g.ndata.pop('h_out')\n",
        "    return out\n",
        "\n",
        "class DGL_SAGEConv(nn.Module):\n",
        "  def __init__(self, in_channel, out_channel):\n",
        "    super().__init__()\n",
        "    self.lin = nn.Linear(2*in_channel, out_channel)\n",
        "\n",
        "    nn.init.xavier_uniform_(self.lin.weight, gain=1.414)\n",
        "    if self.lin.bias is not None:\n",
        "      nn.init.zeros_(self.lin.bias)\n",
        "\n",
        "  def forward(self, g, h):\n",
        "    g = dgl.add_self_loop(g)\n",
        "    g.ndata['h'] = h\n",
        "\n",
        "    def msg_func(edges):\n",
        "      return {'m': edges.src['h']}\n",
        "\n",
        "    g.update_all(\n",
        "      msg_func,\n",
        "      fn.mean('m', 'agg_neighbors')\n",
        "    )\n",
        "\n",
        "    x_concat = torch.cat([g.ndata['h'], g.ndata['agg_neighbors']], dim=-1)\n",
        "\n",
        "    out = self.lin(x_concat)\n",
        "    return out"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G955HzNxVjSu"
      },
      "source": [
        "If you want to check your answer, you can run the following code."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "PKgfXLyLVwus"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[-0.9622,  0.8724,  1.7199, -0.5196],\n",
            "        [-0.9622,  0.8724,  1.7199, -0.5196],\n",
            "        [-0.9622,  0.8724,  1.7199, -0.5196],\n",
            "        [-0.9622,  0.8724,  1.7199, -0.5196],\n",
            "        [-0.9622,  0.8724,  1.7199, -0.5196]], grad_fn=<ScatterAddBackward0>)\n",
            "tensor([[ 1.8194, -2.2228,  3.6659,  1.1293],\n",
            "        [ 1.8194, -2.2228,  3.6659,  1.1293],\n",
            "        [ 1.8194, -2.2228,  3.6659,  1.1293],\n",
            "        [ 1.8194, -2.2228,  3.6659,  1.1293],\n",
            "        [ 1.8194, -2.2228,  3.6659,  1.1293]], grad_fn=<AddmmBackward0>)\n",
            "tensor([[ 0.7014, -1.0442,  0.0533,  2.7487],\n",
            "        [ 0.7014, -1.0442,  0.0533,  2.7487],\n",
            "        [ 0.7014, -1.0442,  0.0533,  2.7487],\n",
            "        [ 0.7014, -1.0442,  0.0533,  2.7487],\n",
            "        [ 0.7014, -1.0442,  0.0533,  2.7487]], grad_fn=<GSpMMBackward>)\n",
            "tensor([[-1.6457, -3.3782, -1.0880, -0.9941],\n",
            "        [-1.6457, -3.3782, -1.0880, -0.9941],\n",
            "        [-1.6457, -3.3782, -1.0880, -0.9941],\n",
            "        [-1.6457, -3.3782, -1.0880, -0.9941],\n",
            "        [-1.6457, -3.3782, -1.0880, -0.9941]], grad_fn=<AddmmBackward0>)\n"
          ]
        }
      ],
      "source": [
        "edge_index = torch.tensor([[0,1,1,2,2,4],[2,0,2,3,4,3]])\n",
        "x = torch.ones((5, 8))\n",
        "conv = PyG_GATConv(8, 4)\n",
        "output = conv(x, edge_index)\n",
        "print(output)\n",
        "conv = PyG_SAGEConv(8, 4)\n",
        "output = conv(x, edge_index)\n",
        "print(output)\n",
        "\n",
        "src = torch.tensor([0, 1, 1, 2, 2, 4])\n",
        "dst = torch.tensor([2, 0, 2, 3, 4, 3])\n",
        "h = torch.ones((5, 8))\n",
        "g = dgl.graph((src, dst))\n",
        "conv = DGL_GATConv(8, 4)\n",
        "output = conv(g, h)\n",
        "print(output)\n",
        "conv = DGL_SAGEConv(8, 4)\n",
        "output = conv(g, h)\n",
        "print(output)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "PyG",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.19"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
